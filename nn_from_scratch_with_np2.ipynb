{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zw1jIj5O10SH"
   },
   "source": [
    "# Neuronal Network from Scratch with numpy Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_No9Csms22Wx"
   },
   "source": [
    "This notebook is only a minimal extension of the first notebook. The only thing we add here is a second output neuron. The activation function, the data and the rest of the architecture remain the same.\n",
    "\n",
    "## Architecture\n",
    "<img src=\"img/nn_2.png\" style=\"height:250px\">\n",
    "\n",
    "## Loss Function\n",
    "As loss-function we use again the Mean Squared Error $L=\\frac{1}{n}\\sum_{i=1}^n (y_1-\\hat{y}_1)^2 + (y_2-\\hat{y}_2)^2$, with $\\hat{y}_i=o_i$ beeing the predicted labels (genders) and $y_i$ beeing the given labels of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIa08I1y1qO1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1578176190206,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -60
    },
    "id": "j8ZwIgMdOqwQ",
    "outputId": "9a4ac973-d52b-4dc3-db32-287a22c618ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data:\n",
      "      name  weight  height gender\n",
      "0    Alice     133      65      F\n",
      "1      Bob     160      72      M\n",
      "2  Charlie     152      70      M\n",
      "3    Diana     120      60      F\n",
      "normalized training_data:\n",
      "      name    weight    height  gender\n",
      "0    Alice -0.454895 -0.325435       1\n",
      "1      Bob  1.033852  0.976304       0\n",
      "2  Charlie  0.592742  0.604379       0\n",
      "3    Diana -1.171699 -1.255248       1\n",
      "\n",
      "prediction_data:\n",
      "    name  weight  height\n",
      "0  Emily     128      63\n",
      "1  Frank     155      68\n",
      "normalized prediction_data:\n",
      "    name    weight    height\n",
      "0  Emily -0.730589 -0.697360\n",
      "1  Frank  0.758158  0.232453\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.DataFrame({'name':   ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
    "                              'weight': [133, 160, 152, 120],\n",
    "                              'height': [65, 72, 70, 60],\n",
    "                              'gender': ['F', 'M', 'M', 'F']})\n",
    "print('training_data:')\n",
    "print(training_data)\n",
    "\n",
    "# replace 'F' with 1 and 'M' with 0\n",
    "training_data['gender'].replace(to_replace=['F','M'], value=[1,0], inplace=True)\n",
    "\n",
    "# normalize weight and height\n",
    "mean = {}\n",
    "std = {}\n",
    "for i in ['weight', 'height']:\n",
    "  mean[i] = training_data[i].mean()\n",
    "  std[i] = training_data[i].std()\n",
    "  training_data[i] = (training_data[i] - mean[i]) / std[i]\n",
    "  \n",
    "print('normalized training_data:')\n",
    "print(training_data)\n",
    "\n",
    "data = training_data[['weight', 'height']].to_numpy()\n",
    "\n",
    "all_y_trues = training_data['gender'].to_numpy()\n",
    "all_y_trues = np.array([all_y_trues, 1-all_y_trues]).T\n",
    "\n",
    "# F - (1,0), M - (0,1)\n",
    "all_y_trues = list(zip(all_y_trues, 1-all_y_trues))\n",
    "\n",
    "prediction_data = pd.DataFrame({'name':   ['Emily', 'Frank'],\n",
    "                                'weight': [128, 155],\n",
    "                                'height': [63, 68]})\n",
    "print('\\nprediction_data:')\n",
    "print(prediction_data)\n",
    "\n",
    "# normalize weight and height\n",
    "for i in ['weight', 'height']:\n",
    "  prediction_data[i] = (prediction_data[i] - mean[i]) / std[i]\n",
    "\n",
    "print('normalized prediction_data:')\n",
    "print(prediction_data)\n",
    "\n",
    "pred_data = prediction_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247516,
     "status": "ok",
     "timestamp": 1578177669929,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -60
    },
    "id": "8FqUkKRbPDE8",
    "outputId": "c59a2739-5f28-4253-a541-24b97bff9bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.51981\n",
      "Epoch 20 loss: 0.43643\n",
      "Epoch 40 loss: 0.36270\n",
      "Epoch 60 loss: 0.28155\n",
      "Epoch 80 loss: 0.20956\n",
      "Epoch 100 loss: 0.15504\n",
      "Epoch 120 loss: 0.11674\n",
      "Epoch 140 loss: 0.09033\n",
      "Epoch 160 loss: 0.07191\n",
      "Epoch 180 loss: 0.05876\n",
      "Epoch 200 loss: 0.04910\n",
      "Epoch 220 loss: 0.04182\n",
      "Epoch 240 loss: 0.03620\n",
      "Epoch 260 loss: 0.03176\n",
      "Epoch 280 loss: 0.02819\n",
      "Epoch 300 loss: 0.02527\n",
      "Epoch 320 loss: 0.02285\n",
      "Epoch 340 loss: 0.02081\n",
      "Epoch 360 loss: 0.01908\n",
      "Epoch 380 loss: 0.01759\n",
      "Epoch 400 loss: 0.01630\n",
      "Epoch 420 loss: 0.01517\n",
      "Epoch 440 loss: 0.01418\n",
      "Epoch 460 loss: 0.01330\n",
      "Epoch 480 loss: 0.01251\n",
      "Epoch 500 loss: 0.01181\n",
      "Epoch 520 loss: 0.01118\n",
      "Epoch 540 loss: 0.01061\n",
      "Epoch 560 loss: 0.01009\n",
      "Epoch 580 loss: 0.00961\n",
      "Epoch 600 loss: 0.00918\n",
      "Epoch 620 loss: 0.00878\n",
      "Epoch 640 loss: 0.00841\n",
      "Epoch 660 loss: 0.00807\n",
      "Epoch 680 loss: 0.00775\n",
      "Epoch 700 loss: 0.00746\n",
      "Epoch 720 loss: 0.00719\n",
      "Epoch 740 loss: 0.00693\n",
      "Epoch 760 loss: 0.00670\n",
      "Epoch 780 loss: 0.00647\n",
      "Epoch 800 loss: 0.00626\n",
      "Epoch 820 loss: 0.00607\n",
      "Epoch 840 loss: 0.00588\n",
      "Epoch 860 loss: 0.00571\n",
      "Epoch 880 loss: 0.00554\n",
      "Epoch 900 loss: 0.00539\n",
      "Epoch 920 loss: 0.00524\n",
      "Epoch 940 loss: 0.00510\n",
      "Epoch 960 loss: 0.00496\n",
      "Epoch 980 loss: 0.00484\n",
      "loss:  0.004721505497930113\n",
      "best_loss:  0.004721505497930113\n",
      "Emily [[0.96505407 0.05150198]\n",
      " [0.03443064 0.94846965]]\n",
      "Frank [[0.09367608 0.93004671]\n",
      " [0.90624428 0.0687856 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_trues, y_preds):\n",
    "  # y_trues and y_preds are numpy arrays of the same length.\n",
    "  diff = np.square(y_trues - y_preds)\n",
    "  return np.mean(np.apply_along_axis(np.sum, 1, diff))\n",
    "\n",
    "class NeuralNetwork:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 2 neurons (o1, o2)\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Weights\n",
    "    self.w1 = np.random.normal()\n",
    "    self.w2 = np.random.normal()\n",
    "    self.w3 = np.random.normal()\n",
    "    self.w4 = np.random.normal()\n",
    "    self.w5 = np.random.normal()\n",
    "    self.w6 = np.random.normal()\n",
    "    self.w7 = np.random.normal()\n",
    "    self.w8 = np.random.normal()\n",
    "\n",
    "    # Biases\n",
    "    self.b1 = np.random.normal()\n",
    "    self.b2 = np.random.normal()\n",
    "    self.b3 = np.random.normal()\n",
    "    self.b4 = np.random.normal()\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "    o2 = sigmoid(self.w7 * h1 + self.w8 * h2 + self.b4)\n",
    "    return o1, o2\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "    '''\n",
    "    - data is a (n x 2) numpy array, n = # of samples in the dataset.\n",
    "    - all_y_trues is a (n x 2) numpy array with n elements.\n",
    "    '''\n",
    "    learn_rate = 0.1\n",
    "    epochs = 1000 # number of times to loop through the entire dataset\n",
    "    y_pred = [0,0]\n",
    "    \n",
    "    loss = 100\n",
    "\n",
    "    # plot loss during training\n",
    "    fig1, ax1 = plt.subplots(figsize=(5,5))\n",
    "    ax1.set_title('Mean Square Loss Error')\n",
    "    for epoch in range(epochs):\n",
    "      for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Do a feedforward (we'll need these values later)\n",
    "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred[0] = o1\n",
    "\n",
    "        sum_o2 = self.w7 * h1 + self.w8 * h2 + self.b4\n",
    "        o2 = sigmoid(sum_o2)\n",
    "        y_pred[1] = o2\n",
    "\n",
    "        # --- Calculate partial derivatives.\n",
    "        # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
    "        d_L_d_ypred1 = -2 * (y_true[0] - y_pred[0])\n",
    "        d_L_d_ypred2 = -2 * (y_true[1] - y_pred[1])\n",
    "\n",
    "        # - Neuron o1\n",
    "        d_ypred1_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred1_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred1_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # - Neuron o2\n",
    "        d_ypred2_d_w7 = h1 * deriv_sigmoid(sum_o2)\n",
    "        d_ypred2_d_w8 = h2 * deriv_sigmoid(sum_o2)\n",
    "        d_ypred2_d_b4 = deriv_sigmoid(sum_o2)\n",
    "\n",
    "        # - Neuron h1\n",
    "        d_ypred1_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred2_d_h1 = self.w7 * deriv_sigmoid(sum_o2)\n",
    "        \n",
    "        # w2\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_ypred1_d_w2 = d_ypred1_d_h1 * d_h1_d_w2\n",
    "        d_ypred2_d_w2 = d_ypred2_d_h1 * d_h1_d_w2\n",
    "        d_L_d_w2 = d_L_d_ypred1 * d_ypred1_d_w2 + d_L_d_ypred2 * d_ypred2_d_w2\n",
    "\n",
    "        # w1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_ypred1_d_w1 = d_ypred1_d_h1 * d_h1_d_w1\n",
    "        d_ypred2_d_w1 = d_ypred2_d_h1 * d_h1_d_w1\n",
    "        d_L_d_w1 = d_L_d_ypred1 * d_ypred1_d_w1 + d_L_d_ypred2 * d_ypred2_d_w1\n",
    "\n",
    "        # Neuron h2\n",
    "        d_ypred1_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred2_d_h2 = self.w8 * deriv_sigmoid(sum_o2)\n",
    "\n",
    "        # w4\n",
    "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_ypred1_d_w4 = d_ypred1_d_h2 * d_h2_d_w4\n",
    "        d_ypred2_d_w4 = d_ypred2_d_h2 * d_h2_d_w4\n",
    "        # w4 influences the loss function via y_pred1 as well as via y_pred2\n",
    "        d_L_d_w4 = d_L_d_ypred1 * d_ypred1_d_w4 + d_L_d_ypred2 * d_ypred2_d_w4\n",
    "\n",
    "        # w3\n",
    "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_ypred1_d_w3 = d_ypred1_d_h2 * d_h2_d_w3\n",
    "        d_ypred2_d_w3 = d_ypred2_d_h2 * d_h2_d_w3\n",
    "        d_L_d_w3 = d_L_d_ypred1 * d_ypred1_d_w3 + d_L_d_ypred2 * d_ypred2_d_w3\n",
    "\n",
    "        # b2\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "        d_ypred1_d_b2 = d_ypred1_d_h2 * d_h2_d_b2\n",
    "        d_ypred2_d_b2 = d_ypred2_d_h2 * d_h2_d_b2\n",
    "        d_L_d_b2 = d_L_d_ypred1 * d_ypred1_d_b2 + d_L_d_ypred2 * d_ypred2_d_b2\n",
    "\n",
    "        # b1\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "        d_ypred1_d_b1 = d_ypred1_d_h1 * d_h1_d_b1\n",
    "        d_ypred2_d_b1 = d_ypred2_d_h1 * d_h1_d_b1\n",
    "        d_L_d_b1 = d_L_d_ypred1 * d_ypred1_d_b1 + d_L_d_ypred2 * d_ypred2_d_b1\n",
    "\n",
    "        # --- Update weights and biases\n",
    "        # Weights\n",
    "        \n",
    "        # Neuron o1\n",
    "        self.w5 -= learn_rate * d_L_d_ypred1 * d_ypred1_d_w5\n",
    "        self.w6 -= learn_rate * d_L_d_ypred1 * d_ypred1_d_w6\n",
    "        self.b3 -= learn_rate * d_L_d_ypred1 * d_ypred1_d_b3\n",
    "\n",
    "        # Neuron o2\n",
    "        self.w7 -= learn_rate * d_L_d_ypred2 * d_ypred2_d_w7\n",
    "        self.w8 -= learn_rate * d_L_d_ypred2 * d_ypred2_d_w8\n",
    "        self.b4 -= learn_rate * d_L_d_ypred2 * d_ypred2_d_b4\n",
    "\n",
    "        # Neuron h1\n",
    "        self.w1 -= learn_rate * d_L_d_w1\n",
    "        self.w2 -= learn_rate * d_L_d_w2\n",
    "        self.b1 -= learn_rate * d_L_d_b1\n",
    "\n",
    "        # Neuron h2\n",
    "        self.w3 -= learn_rate * d_L_d_w3\n",
    "        self.w4 -= learn_rate * d_L_d_w4\n",
    "        self.b2 -= learn_rate * d_L_d_b2\n",
    "\n",
    "      # --- Calculate total loss\n",
    "      # get predictions for all samples from data\n",
    "      # apply feedforward along x axis\n",
    "      y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
    "      if loss < mse_loss(all_y_trues, y_preds):\n",
    "        break\n",
    "      loss = mse_loss(all_y_trues, y_preds)\n",
    "      ax1.scatter(epoch, loss, marker='.', c='b')\n",
    "\n",
    "      if epoch % 20 == 0:\n",
    "        print(\"Epoch %d loss: %.5f\" % (epoch, loss))\n",
    "\n",
    "    #plt.show()\n",
    "    print('loss: ', loss)\n",
    "\n",
    "# Train our neural network!\n",
    "best_network = NeuralNetwork()\n",
    "best_network.train(data, all_y_trues)\n",
    "best_loss = mse_loss(all_y_trues, np.apply_along_axis(best_network.feedforward, 1, data))\n",
    "\n",
    "#for i in range(1,10):\n",
    "#  network = NeuralNetwork()\n",
    "#  network.train(data, all_y_trues)\n",
    "#  if mse_loss(all_y_trues, np.apply_along_axis(best_network.feedforward, 1, data)) < best_loss:\n",
    "#    best_loss = mse_loss(all_y_trues, np.apply_along_axis(best_network.feedforward, 1, data))\n",
    "#    best_network = network\n",
    "\n",
    "print('best_loss: ', best_loss)\n",
    "\n",
    "# Make some predictions\n",
    "y_preds = np.apply_along_axis(best_network.feedforward, 1, pred_data[:,1:3])\n",
    "for i in range(len(y_preds)):\n",
    "  print(pred_data[i,0], y_preds[i])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nn_from_scratch_with_np2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
